{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2ba176",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756cfed2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# adding the project root inside the python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d631aee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The path where the dataset are stored\n",
    "DATASET_PATH: str = \"../../dataset/first_disease_sel/\"\n",
    "DISEASE_COLNAME: str = 'DISEASE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30ec15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Executing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c5f214",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pipeline already executed, found dataset inside /tmp/chl\n",
      "INFO:root:Splitting dataset\n",
      "INFO:root:Pipeline executed\n"
     ]
    }
   ],
   "source": [
    "from analysis.preprocess import PreprocessPipeline\n",
    "\n",
    "pipeline = PreprocessPipeline(\n",
    "    datasets_path=DATASET_PATH,\n",
    "    disease_col_name=DISEASE_COLNAME\n",
    ")\n",
    "pipeline.execute_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab377e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building the Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d460c2",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3cc11e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Executing Grid Search for Decision Tree\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "480 fits failed out of a total of 2400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "480 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 247, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_leaf == 0, must be >= 1.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.62525424 0.64898305\n",
      " 0.69231638 0.66898305 0.63864407 0.63870056 0.64559322 0.62553672\n",
      " 0.68858757 0.68610169 0.68242938 0.70564972 0.68909605 0.63542373\n",
      " 0.65881356 0.64559322 0.64915254 0.64220339 0.64564972 0.65858757\n",
      " 0.68259887 0.63214689 0.65892655 0.66248588 0.69581921 0.65531073\n",
      " 0.64892655 0.70214689 0.65220339 0.63870056 0.63898305 0.68237288\n",
      " 0.68237288 0.64542373 0.65570621 0.64559322 0.67242938 0.65576271\n",
      " 0.68553672 0.66903955 0.66248588 0.65220339 0.70276836 0.7120904\n",
      " 0.65531073 0.69242938 0.65225989 0.69242938 0.6520904  0.66875706\n",
      " 0.67892655 0.68903955 0.68576271 0.68909605 0.71231638 0.69553672\n",
      " 0.69915254 0.66548023 0.68587571 0.69559322 0.60542373 0.63225989\n",
      " 0.63875706 0.66559322        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66242938 0.6319774  0.63587571 0.60847458 0.64853107 0.59553672\n",
      " 0.63531073 0.55548023 0.63875706 0.65875706 0.63887006 0.61214689\n",
      " 0.61225989 0.62875706 0.63909605 0.65553672 0.65231638 0.64576271\n",
      " 0.67220339 0.56514124 0.64581921 0.62220339 0.66536723 0.64553672\n",
      " 0.67903955 0.62220339 0.58870056 0.62898305 0.64525424 0.60870056\n",
      " 0.61892655 0.61881356 0.65581921 0.67581921 0.6920339  0.65214689\n",
      " 0.66248588 0.61858757 0.64909605 0.6119774  0.66898305 0.64564972\n",
      " 0.59214689 0.64548023 0.64870056 0.57519774 0.6959887  0.70898305\n",
      " 0.71559322 0.64870056 0.66909605 0.6219774  0.67898305 0.64564972\n",
      " 0.63175141 0.53548023 0.67225989 0.62892655 0.67892655 0.65548023\n",
      " 0.6319774  0.61841808 0.66576271 0.57858757        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.64898305 0.67214689 0.71220339 0.68564972\n",
      " 0.66920904 0.66564972 0.67225989 0.63553672 0.7259322  0.63508475\n",
      " 0.65564972 0.65559322 0.6820339  0.71553672 0.68542373 0.64231638\n",
      " 0.68903955 0.71587571 0.65231638 0.63887006 0.6420339  0.64887006\n",
      " 0.67559322 0.62525424 0.65881356 0.67559322 0.63570621 0.68570621\n",
      " 0.6820904  0.66576271 0.67559322 0.67570621 0.66531073 0.63242938\n",
      " 0.68892655 0.68225989 0.65887006 0.65926554 0.69892655 0.67864407\n",
      " 0.69898305 0.69242938 0.68887006 0.72248588 0.69225989 0.70536723\n",
      " 0.67531073 0.63875706 0.68564972 0.64548023 0.71248588 0.68225989\n",
      " 0.72254237 0.67225989 0.69564972 0.65553672 0.68920904 0.64214689\n",
      " 0.70581921 0.66875706 0.66903955 0.68548023 0.69242938 0.67214689\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.6019209  0.64909605\n",
      " 0.64875706 0.61853107 0.66220339 0.62881356 0.65892655 0.6420904\n",
      " 0.69915254 0.63542373 0.61559322 0.62214689 0.65858757 0.6620904\n",
      " 0.66231638 0.60542373 0.66231638 0.63542373 0.64898305 0.61864407\n",
      " 0.66903955 0.64564972 0.62864407 0.67548023 0.68220339 0.6620904\n",
      " 0.70559322 0.68581921 0.64887006 0.59881356 0.64887006 0.67242938\n",
      " 0.6619774  0.59875706 0.65553672 0.63548023 0.6420339  0.64553672\n",
      " 0.62525424 0.62875706 0.66231638 0.59858757 0.66909605 0.64231638\n",
      " 0.62915254 0.66915254 0.71564972 0.67231638 0.6720339  0.65559322\n",
      " 0.67570621 0.60548023 0.69237288 0.61870056 0.64542373 0.64559322\n",
      " 0.62909605 0.66870056 0.63531073 0.63220339 0.63553672 0.6220904\n",
      " 0.67881356 0.65864407        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66881356 0.62548023 0.69909605 0.6119774  0.69581921 0.65220339\n",
      " 0.66542373 0.69559322 0.66870056 0.64892655 0.70909605 0.65242938\n",
      " 0.70909605 0.63887006 0.69259887 0.69909605 0.68570621 0.65231638\n",
      " 0.65570621 0.69242938 0.63531073 0.6620904  0.65881356 0.62564972\n",
      " 0.65225989 0.64875706 0.68259887 0.69231638 0.68892655 0.64220339\n",
      " 0.70587571 0.64248588 0.68564972 0.68237288 0.67559322 0.71248588\n",
      " 0.67898305 0.67881356 0.70570621 0.66892655 0.68887006 0.69581921\n",
      " 0.67892655 0.64898305 0.63847458 0.71237288 0.67242938 0.63887006\n",
      " 0.7020904  0.67881356 0.67887006 0.66875706 0.64875706 0.69220339\n",
      " 0.68553672 0.65231638 0.68214689 0.65564972 0.68242938 0.69559322\n",
      " 0.70587571 0.6859887  0.67237288 0.68548023        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.66898305 0.62231638 0.61542373 0.62548023\n",
      " 0.63220339 0.62519774 0.64887006 0.56870056 0.63864407 0.69225989\n",
      " 0.64225989 0.63559322 0.65576271 0.65887006 0.57836158 0.62220339\n",
      " 0.63564972 0.64248588 0.61220339 0.65237288 0.65542373 0.58525424\n",
      " 0.60220339 0.63553672 0.58180791 0.6320904  0.63887006 0.59559322\n",
      " 0.64870056 0.61881356 0.6619209  0.6959887  0.63875706 0.64231638\n",
      " 0.68542373 0.63536723 0.62553672 0.65231638 0.63553672 0.64514124\n",
      " 0.66186441 0.67576271 0.66875706 0.62881356 0.63542373 0.63231638\n",
      " 0.66887006 0.60553672 0.65548023 0.66920904 0.69542373 0.6960452\n",
      " 0.60220339 0.65237288 0.65531073 0.62514124 0.64570621 0.6119774\n",
      " 0.68570621 0.66536723 0.67231638 0.65887006 0.63553672 0.66220339]\n",
      "  warnings.warn(\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 0.98327057 0.97491632 0.97909344 0.9632113  0.96905858 0.9448152\n",
      " 0.96405858 0.93478731 0.94229428 0.92306485 0.93479428 0.9030265\n",
      " 0.91722803 0.89714435 0.95150628 0.92893305 0.95235356 0.93144003\n",
      " 0.95233612 0.93143305 0.95233612 0.92141562 0.93647141 0.90971409\n",
      " 0.93644351 0.90720711 0.92643654 0.88629358 0.91972455 0.88124477\n",
      " 0.936447   0.8846304  0.93478731 0.90720363 0.92392608 0.89213738\n",
      " 0.92894351 0.88880056 0.93895746 0.89882497 0.91972455 0.88294282\n",
      " 0.91221757 0.89047768 0.90468619 0.86036262 0.90552999 0.84613668\n",
      " 0.90051255 0.86120642 0.91303696 0.85953278 0.90302999 0.84698745\n",
      " 0.90550558 0.85788703 0.89716876 0.86203278 0.90885983 0.8653696\n",
      " 0.90301953 0.85618898        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.9849477  0.96738842 0.9740795  0.94650976\n",
      " 0.95317992 0.90716876 0.9423152  0.89801255 0.93394351 0.87457462\n",
      " 0.93561367 0.85619596 0.90719665 0.83612622 0.93645746 0.90049861\n",
      " 0.94063459 0.8762622  0.92809972 0.89548117 0.92894003 0.88376569\n",
      " 0.91721757 0.86620642 0.89967225 0.84114017 0.91136332 0.82359135\n",
      " 0.88211994 0.81940377 0.90383543 0.82609135 0.90470014 0.84029289\n",
      " 0.91804742 0.84113319 0.8988424  0.82692469 0.89798815 0.8352894\n",
      " 0.89213738 0.82525453 0.88711994 0.80516388 0.88713389 0.82191074\n",
      " 0.87207462 0.80017782 0.86372036 0.79096583 0.87708508 0.80100418\n",
      " 0.86957113 0.78427824 0.86955718 0.79347978 0.8712378  0.7909728\n",
      " 0.8620537  0.79935495 0.87122385 0.78177127        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.99330893 0.98495119\n",
      " 0.98412134 0.97658996 0.97324268 0.95233612 0.96572524 0.94481172\n",
      " 0.95652022 0.92895397 0.96069735 0.91222455 0.93895049 0.89381799\n",
      " 0.95902371 0.94815202 0.96320781 0.94314505 0.96821478 0.93728731\n",
      " 0.95736402 0.93812762 0.95402022 0.93227685 0.95653417 0.90636332\n",
      " 0.93562762 0.90215481 0.933947   0.90382845 0.9423152  0.91052999\n",
      " 0.94230474 0.91388075 0.94146792 0.91556137 0.94063459 0.90551953\n",
      " 0.94816248 0.89883543 0.9439749  0.91220711 0.93394351 0.89046374\n",
      " 0.92809972 0.88712692 0.92390865 0.85869944 0.92810321 0.87376569\n",
      " 0.91805788 0.87290446 0.92391213 0.8770781  0.92558926 0.87291492\n",
      " 0.91638773 0.86956764 0.93060669 0.87206764 0.92391213 0.86706764\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 0.98829498 0.97073222 0.97994073 0.93728731 0.96991283 0.92224547\n",
      " 0.96238842 0.89132497 0.93646792 0.86119247 0.92224547 0.84698047\n",
      " 0.91555788 0.8419735  0.95150628 0.90299512 0.96153766 0.90383194\n",
      " 0.95067643 0.90634589 0.95067294 0.87791144 0.92975941 0.87958856\n",
      " 0.93142957 0.85950837 0.91387029 0.84031032 0.90637029 0.82022315\n",
      " 0.92055788 0.83364017 0.91555788 0.86121339 0.91139121 0.84026848\n",
      " 0.91805439 0.84866457 0.90887378 0.84196653 0.91387378 0.83026848\n",
      " 0.91891213 0.83362273 0.90301604 0.813553   0.87625523 0.81019874\n",
      " 0.91054045 0.79349372 0.89046025 0.79179219 0.89465132 0.80435844\n",
      " 0.88795328 0.78930962 0.89381799 0.801841   0.8871304  0.79598326\n",
      " 0.88628312 0.79850418        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.98996513 0.98829498 0.98662134 0.97993375\n",
      " 0.97658996 0.95985356 0.96488145 0.93980126 0.95903766 0.933947\n",
      " 0.95651674 0.91387378 0.95568689 0.90801953 0.95987448 0.94315202\n",
      " 0.97074268 0.94814505 0.96655509 0.94230474 0.95651325 0.93394351\n",
      " 0.9489993  0.93143305 0.95065551 0.90968619 0.94648884 0.91134937\n",
      " 0.94398187 0.8821304  0.9489993  0.91136332 0.94898884 0.90300907\n",
      " 0.93979428 0.91388424 0.93895746 0.91137378 0.94231869 0.91472106\n",
      " 0.93895397 0.90385983 0.93561367 0.88797071 0.92724895 0.87708159\n",
      " 0.91972803 0.86958856 0.9255788  0.88460948 0.91973849 0.87876918\n",
      " 0.91554045 0.87124128 0.92140516 0.87290795 0.9272629  0.87039749\n",
      " 0.92057183 0.87456764 0.92139819 0.8603696         nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.98661437 0.9824477\n",
      " 0.97908647 0.94732566 0.96906206 0.93394003 0.94731172 0.91053696\n",
      " 0.94064854 0.8787378  0.9398152  0.83944561 0.90970711 0.84443863\n",
      " 0.94230823 0.90551604 0.94230823 0.90133891 0.9423152  0.88545676\n",
      " 0.94229428 0.88125174 0.92811018 0.86288703 0.93144003 0.84698745\n",
      " 0.90552301 0.84449093 0.9080265  0.81938633 0.91305439 0.84364714\n",
      " 0.91304045 0.83862622 0.92225244 0.84698396 0.91555439 0.83946653\n",
      " 0.93060669 0.82776499 0.91471757 0.83529637 0.90885635 0.82025453\n",
      " 0.89882845 0.81604951 0.89048466 0.80183403 0.88713389 0.81434449\n",
      " 0.88711646 0.78759763 0.88042538 0.80350767 0.90466527 0.79098675\n",
      " 0.87540795 0.79851116 0.89717573 0.80936541 0.87709902 0.79094491]\n",
      "  warnings.warn(\n",
      "INFO:root:Grid search terminated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Report of GridSearch\n",
      "INFO:root:     rank_test_accuracy  mean_test_accuracy  mean_train_accuracy  \\\n",
      "184                   1            0.725932             0.965725   \n",
      "228                   2            0.722542             0.918058   \n",
      "219                   3            0.722486             0.912207   \n",
      "193                   4            0.715876             0.948152   \n",
      "302                   5            0.715650             0.903016   \n",
      "..                  ...                 ...                  ...   \n",
      "331                 476                 NaN                  NaN   \n",
      "332                 477                 NaN                  NaN   \n",
      "333                 478                 NaN                  NaN   \n",
      "406                 479                 NaN                  NaN   \n",
      "0                   480                 NaN                  NaN   \n",
      "\n",
      "     std_test_accuracy  std_train_accuracy  mean_fit_time  \\\n",
      "184           0.056638            0.009290       0.058269   \n",
      "228           0.023583            0.010129       0.055200   \n",
      "219           0.033696            0.008369       0.046105   \n",
      "193           0.063518            0.006318       0.050759   \n",
      "302           0.030445            0.013022       0.046388   \n",
      "..                 ...                 ...            ...   \n",
      "331                NaN                 NaN       0.050691   \n",
      "332                NaN                 NaN       0.057390   \n",
      "333                NaN                 NaN       0.056418   \n",
      "406                NaN                 NaN       0.050976   \n",
      "0                  NaN                 NaN       0.057873   \n",
      "\n",
      "                                                params  \n",
      "184  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "228  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "219  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "193  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "302  {'criterion': 'entropy', 'max_features': 'log2...  \n",
      "..                                                 ...  \n",
      "331  {'criterion': 'log_loss', 'max_features': 'sqr...  \n",
      "332  {'criterion': 'log_loss', 'max_features': 'sqr...  \n",
      "333  {'criterion': 'log_loss', 'max_features': 'sqr...  \n",
      "406  {'criterion': 'log_loss', 'max_features': 'log...  \n",
      "0    {'criterion': 'gini', 'max_features': 'sqrt', ...  \n",
      "\n",
      "[480 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from analysis.classifiers.dt import build_parameters\n",
    "\n",
    "hyper_params = build_parameters(\n",
    "    train_x=pipeline.train_x,\n",
    "    train_y=pipeline.train_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0c813",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec94d63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;sqrt&#x27;,\n",
       "                       min_samples_split=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;sqrt&#x27;,\n",
       "                       min_samples_split=6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_features='sqrt',\n",
       "                       min_samples_split=6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis.classifiers.dt import build_model\n",
    "\n",
    "decision_tree = build_model(\n",
    "    train_x=pipeline.train_x,\n",
    "    train_y=pipeline.train_y,\n",
    "    best_params=hyper_params\n",
    ")\n",
    "decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623a11c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf4e8158",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from analysis.classifiers.dt import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ea0824",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         A1A       0.97      0.91      0.94        32\n",
      "     DIABETE       0.70      0.75      0.73        44\n",
      "          GS       0.36      0.71      0.48         7\n",
      "         MCM       0.50      0.43      0.46         7\n",
      "        NALD       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.64      0.60      0.58       100\n",
      "weighted avg       0.74      0.72      0.71       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation = evaluate_model(\n",
    "    decision_tree=decision_tree,\n",
    "    test_x=pipeline.test_x,\n",
    "    test_y=pipeline.test_y\n",
    ")\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1fc8a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17504635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}