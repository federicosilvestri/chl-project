{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2ba176",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756cfed2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# adding the project root inside the python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d631aee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The path where the dataset are stored\n",
    "DATASET_PATH: str = \"../../dataset/first_disease_sel/\"\n",
    "DISEASE_COLNAME: str = 'DISEASE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30ec15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Executing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c5f214",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting pipeline\n",
      "INFO:root:Loading datasets\n",
      "INFO:root:Inspecting directory ../../dataset/first_disease_sel/GS\n",
      "INFO:root:Setting disease as GS\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/GS/eGSE117146m.csv\n",
      "INFO:root:Inspecting directory ../../dataset/first_disease_sel/MCM\n",
      "INFO:root:Setting disease as MCM\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/MCM/MCM_GSE149607.csv\n",
      "INFO:root:Inspecting directory ../../dataset/first_disease_sel/NALD\n",
      "INFO:root:Setting disease as NALD\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/NALD/eGSE85804m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/NALD/eGSE34308m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/NALD/eGSE117647m.csv\n",
      "INFO:root:Inspecting directory ../../dataset/first_disease_sel/A1A\n",
      "INFO:root:Setting disease as A1A\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/A1A/A1A_deficiency_GSE109516_pbmc.csv\n",
      "INFO:root:Inspecting directory ../../dataset/first_disease_sel/DIABETE\n",
      "INFO:root:Setting disease as DIABETE\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE54350m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE26887m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE174475m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE13760m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE38642m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE19790m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE179568m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE189849m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE25462m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE162622m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE27949m.csv\n",
      "INFO:root:Loading file ../../dataset/first_disease_sel/DIABETE/eGSE176230m.csv\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Load completed\n",
      "INFO:root:Datasets loading completed\n",
      "INFO:root:Computing column intersection\n",
      "INFO:root:Cleaning datasets from not-shared data\n",
      "INFO:root:Computing outlier detection\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Computing outlier detection on dataset...\n",
      "INFO:root:Compute the scaling of data\n",
      "INFO:root:Building unique dataset\n",
      "INFO:root:Splitting dataset into test and train\n",
      "INFO:root:Storing dataset\n",
      "INFO:root:Creating directory /tmp/chl\n",
      "INFO:root:Saving entire dataset\n",
      "INFO:root:Dataset saved into /tmp/chl\n",
      "INFO:root:Splitting dataset\n",
      "INFO:root:Pipeline executed\n"
     ]
    }
   ],
   "source": [
    "from analysis.preprocess import PreprocessPipeline\n",
    "\n",
    "pipeline = PreprocessPipeline(\n",
    "    datasets_path=DATASET_PATH,\n",
    "    disease_col_name=DISEASE_COLNAME\n",
    ")\n",
    "pipeline.execute_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab377e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building the Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d460c2",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3cc11e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Executing Grid Search for Decision Tree\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "480 fits failed out of a total of 2400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "480 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 247, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_leaf == 0, must be >= 1.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.66875706 0.62508475\n",
      " 0.65564972 0.65920904 0.67915254 0.63542373 0.68570621 0.64881356\n",
      " 0.63237288 0.60881356 0.63559322 0.64881356 0.6619209  0.6520339\n",
      " 0.61548023 0.64231638 0.65887006 0.65220339 0.66587571 0.64909605\n",
      " 0.6519209  0.68892655 0.71920904 0.65559322 0.64542373 0.67265537\n",
      " 0.69559322 0.66903955 0.66887006 0.63220339 0.70892655 0.66887006\n",
      " 0.64887006 0.6519774  0.67553672 0.66564972 0.64898305 0.63892655\n",
      " 0.63548023 0.66570621 0.66903955 0.72254237 0.65220339 0.67576271\n",
      " 0.66920904 0.67559322 0.67548023 0.6220339  0.65220339 0.69237288\n",
      " 0.66214689 0.67898305 0.68254237 0.70248588 0.70564972 0.65570621\n",
      " 0.68898305 0.64514124 0.66242938 0.68559322 0.71553672 0.65548023\n",
      " 0.65220339 0.68903955        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59870056 0.58870056 0.6120904  0.60514124 0.62858757 0.61898305\n",
      " 0.62915254 0.67220339 0.64570621 0.6520904  0.63841808 0.60870056\n",
      " 0.66248588 0.53152542 0.63570621 0.66887006 0.63559322 0.5919774\n",
      " 0.64548023 0.60542373 0.68254237 0.63514124 0.66564972 0.65887006\n",
      " 0.64548023 0.64892655 0.65254237 0.67858757 0.63548023 0.61525424\n",
      " 0.64881356 0.68553672 0.64903955 0.66898305 0.66915254 0.64220339\n",
      " 0.61892655 0.64858757 0.63903955 0.65214689 0.63892655 0.65892655\n",
      " 0.59214689 0.62542373 0.60870056 0.61881356 0.61531073 0.65881356\n",
      " 0.64225989 0.65870056 0.63892655 0.63214689 0.63881356 0.65548023\n",
      " 0.71581921 0.68909605 0.66536723 0.64892655 0.64519774 0.60881356\n",
      " 0.63870056 0.65220339 0.64225989 0.6020339         nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.66564972 0.68892655 0.68926554 0.66248588\n",
      " 0.6859322  0.65881356 0.65531073 0.66892655 0.70559322 0.68242938\n",
      " 0.68864407 0.68242938 0.70903955 0.70231638 0.65864407 0.62542373\n",
      " 0.70225989 0.68548023 0.64864407 0.63559322 0.74259887 0.67576271\n",
      " 0.68915254 0.72242938 0.67248588 0.67564972 0.69892655 0.65864407\n",
      " 0.68903955 0.65909605 0.71237288 0.68903955 0.65909605 0.68220339\n",
      " 0.68920904 0.63548023 0.68242938 0.66875706 0.7060452  0.65576271\n",
      " 0.69564972 0.67932203 0.64903955 0.66892655 0.69587571 0.63214689\n",
      " 0.66254237 0.67570621 0.67887006 0.68231638 0.65892655 0.67564972\n",
      " 0.69892655 0.69237288 0.72220339 0.69225989 0.65559322 0.65564972\n",
      " 0.70909605 0.64553672 0.67909605 0.64564972 0.67564972 0.65564972\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.64887006 0.61864407\n",
      " 0.59519774 0.5920339  0.60898305 0.6319774  0.62881356 0.63903955\n",
      " 0.65242938 0.63887006 0.63531073 0.63559322 0.65564972 0.64548023\n",
      " 0.6520904  0.65881356 0.68237288 0.6619209  0.69892655 0.60903955\n",
      " 0.61548023 0.6719209  0.65214689 0.64920904 0.60570621 0.62875706\n",
      " 0.61858757 0.62231638 0.64881356 0.65576271 0.64903955 0.63570621\n",
      " 0.66542373 0.63892655 0.65853107 0.63881356 0.64225989 0.65576271\n",
      " 0.66875706 0.62536723 0.6220339  0.62892655 0.66909605 0.67564972\n",
      " 0.68898305 0.66231638 0.64548023 0.57870056 0.63525424 0.61225989\n",
      " 0.67254237 0.68576271 0.67553672 0.66870056 0.69231638 0.59531073\n",
      " 0.6819209  0.67870056 0.68576271 0.64892655 0.66576271 0.62548023\n",
      " 0.66559322 0.61536723        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66175141 0.61858757 0.66254237 0.68214689 0.69242938 0.66887006\n",
      " 0.70920904 0.69271186 0.67237288 0.69542373 0.68920904 0.64576271\n",
      " 0.68943503 0.70903955 0.67225989 0.64892655 0.64853107 0.61542373\n",
      " 0.68564972 0.66225989 0.67231638 0.61514124 0.68581921 0.64881356\n",
      " 0.69915254 0.63553672 0.70932203 0.63887006 0.64926554 0.64536723\n",
      " 0.68576271 0.66887006 0.68903955 0.64559322 0.67225989 0.66559322\n",
      " 0.67853107 0.69237288 0.65581921 0.68898305 0.68915254 0.64180791\n",
      " 0.68576271 0.62214689 0.68231638 0.67881356 0.65875706 0.64220339\n",
      " 0.71231638 0.66242938 0.68909605 0.68564972 0.65887006 0.69564972\n",
      " 0.70548023 0.67587571 0.69903955 0.65892655 0.69898305 0.67881356\n",
      " 0.6720904  0.71259887 0.66548023 0.70587571        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.6420339  0.64920904 0.63581921 0.60847458\n",
      " 0.64875706 0.60841808 0.65881356 0.62892655 0.60519774 0.60864407\n",
      " 0.60531073 0.65576271 0.68564972 0.66892655 0.66870056 0.65898305\n",
      " 0.66887006 0.67214689 0.6520339  0.5719209  0.69237288 0.65887006\n",
      " 0.64881356 0.70909605 0.6420904  0.63531073 0.62542373 0.64853107\n",
      " 0.61875706 0.63875706 0.63892655 0.62214689 0.65898305 0.66225989\n",
      " 0.65248588 0.6019774  0.66570621 0.65564972 0.64576271 0.6019774\n",
      " 0.60864407 0.66903955 0.6719774  0.5919209  0.61519774 0.6320339\n",
      " 0.6619774  0.60519774 0.6220339  0.67542373 0.63542373 0.64237288\n",
      " 0.65909605 0.5919209  0.6719209  0.63548023 0.65875706 0.64553672\n",
      " 0.63875706 0.59231638 0.67875706 0.65887006 0.65564972 0.67231638]\n",
      "  warnings.warn(\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 0.98746165 0.98077406 0.97909693 0.9606834  0.9623675  0.94231869\n",
      " 0.9657113  0.93645746 0.94981869 0.91724547 0.94230823 0.89044979\n",
      " 0.93312064 0.87288006 0.95233264 0.92724895 0.948159   0.92974895\n",
      " 0.95987448 0.93226639 0.9448152  0.92140167 0.93395397 0.92055788\n",
      " 0.93311715 0.90216179 0.92807183 0.88713738 0.91637378 0.8770781\n",
      " 0.92892957 0.90048466 0.92391911 0.88211297 0.93311018 0.89129358\n",
      " 0.93061367 0.89633543 0.92055788 0.8946583  0.91889819 0.89966179\n",
      " 0.92306834 0.86619596 0.91471409 0.86621339 0.91388424 0.86453975\n",
      " 0.8954742  0.86118201 0.91051953 0.8645537  0.90550907 0.86705021\n",
      " 0.9097106  0.85955021 0.90635983 0.85452232 0.90801953 0.85702929\n",
      " 0.90049512 0.85116806        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.98077755 0.96572873 0.96572524 0.94314156\n",
      " 0.95400628 0.92142259 0.95148536 0.89800558 0.93645049 0.86287657\n",
      " 0.91222106 0.8336053  0.91054045 0.84698745 0.93478731 0.89633891\n",
      " 0.931447   0.89130753 0.9531834  0.89131799 0.92726639 0.87289749\n",
      " 0.90635286 0.85116806 0.9021583  0.84112971 0.9038424  0.84117503\n",
      " 0.87873082 0.81103556 0.90635635 0.82858787 0.8996583  0.83528591\n",
      " 0.89549163 0.83109833 0.90217573 0.82776848 0.9013424  0.84196304\n",
      " 0.88711994 0.82525105 0.87792887 0.81770223 0.87792887 0.80769526\n",
      " 0.88376918 0.81017782 0.87877266 0.7960007  0.88126569 0.7993166\n",
      " 0.8787622  0.78762901 0.87290795 0.78091702 0.88377615 0.78427824\n",
      " 0.87626569 0.80102162 0.87290098 0.78262204        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.99247559 0.98578801\n",
      " 0.98410739 0.97491632 0.98327406 0.95485356 0.97825662 0.950659\n",
      " 0.96070781 0.93226987 0.95903068 0.91805091 0.9548431  0.88963738\n",
      " 0.9657113  0.95067643 0.96321827 0.93980823 0.96571827 0.9439749\n",
      " 0.95651674 0.933947   0.95735704 0.92224198 0.95735704 0.90468619\n",
      " 0.94146792 0.89465132 0.93646792 0.90133891 0.93646444 0.9013424\n",
      " 0.95150628 0.90552999 0.94062413 0.90051255 0.94983612 0.90552301\n",
      " 0.9414749  0.91138424 0.93979428 0.90551255 0.93228033 0.88630056\n",
      " 0.93225593 0.88378312 0.92140865 0.88295328 0.92809275 0.87290446\n",
      " 0.92391562 0.87541144 0.90718271 0.87541492 0.92307183 0.86871688\n",
      " 0.91889819 0.87876918 0.92391213 0.86955718 0.91638424 0.8578417\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 0.9933159  0.97156206 0.97072873 0.95650976 0.9673954  0.90887727\n",
      " 0.95149582 0.89380404 0.93979428 0.88127266 0.92389819 0.86456416\n",
      " 0.90134937 0.82522315 0.95234658 0.88711994 0.94983612 0.8988145\n",
      " 0.9565272  0.90135635 0.93896095 0.88460948 0.92641562 0.86371339\n",
      " 0.91051953 0.85786611 0.91222106 0.84283124 0.90468271 0.8327894\n",
      " 0.91220363 0.84364365 0.91556137 0.84616109 0.9105265  0.84450837\n",
      " 0.91304045 0.84281381 0.91721409 0.8486855  0.92141911 0.81687587\n",
      " 0.90386681 0.82610879 0.90469317 0.80688633 0.89297768 0.80519874\n",
      " 0.88545676 0.81102859 0.89297071 0.796841   0.8862901  0.78512204\n",
      " 0.88798117 0.78761855 0.89381102 0.79348326 0.88376918 0.78176778\n",
      " 0.8929742  0.81855649        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.99080544 0.98578452 0.98243724 0.97575662\n",
      " 0.97324616 0.96570432 0.96571478 0.94483961 0.95567992 0.92142259\n",
      " 0.95234658 0.91890167 0.94145397 0.89632497 0.96906206 0.9414749\n",
      " 0.96154114 0.93811367 0.9698954  0.94146792 0.95902371 0.93061018\n",
      " 0.95567992 0.92977685 0.94566248 0.91138773 0.94984658 0.89381102\n",
      " 0.94733612 0.88627615 0.93729777 0.91555091 0.95066597 0.90218271\n",
      " 0.93979428 0.90970014 0.94482566 0.90718271 0.93894003 0.90719317\n",
      " 0.94480474 0.89297071 0.92893305 0.88712343 0.92223849 0.87959205\n",
      " 0.92978382 0.8612099  0.91889819 0.86201883 0.91471757 0.87291492\n",
      " 0.92140516 0.87709205 0.92559275 0.87123082 0.92224198 0.87291492\n",
      " 0.92224547 0.88461297 0.91640167 0.8645537         nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.98996513 0.97493724\n",
      " 0.97574268 0.94314854 0.9682357  0.92809623 0.94730823 0.90215481\n",
      " 0.9398152  0.8837901  0.92141562 0.8620258  0.91473152 0.83694909\n",
      " 0.95569386 0.89214086 0.95316597 0.90050558 0.95653417 0.90385286\n",
      " 0.93811715 0.88379358 0.92977336 0.86121339 0.92140865 0.86038006\n",
      " 0.90301604 0.84949093 0.90131102 0.82691423 0.9197106  0.84447001\n",
      " 0.92475941 0.83694561 0.92307183 0.83779637 0.91303696 0.83112622\n",
      " 0.91556137 0.85703278 0.91055091 0.82276848 0.90635983 0.84031032\n",
      " 0.90215481 0.81018828 0.8896304  0.80688285 0.88546025 0.81604254\n",
      " 0.8837622  0.79348675 0.89548815 0.79011506 0.89129707 0.80268131\n",
      " 0.88210948 0.79596932 0.88461297 0.80264296 0.88212343 0.80601116]\n",
      "  warnings.warn(\n",
      "INFO:root:Grid search terminated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Report of GridSearch\n",
      "INFO:root:     rank_test_accuracy  mean_test_accuracy  mean_train_accuracy  \\\n",
      "196                   1            0.742599             0.965718   \n",
      "57                    2            0.722542             0.894658   \n",
      "199                   3            0.722429             0.933947   \n",
      "230                   4            0.722203             0.907183   \n",
      "38                    5            0.719209             0.944815   \n",
      "..                  ...                 ...                  ...   \n",
      "81                  476                 NaN                  NaN   \n",
      "80                  477                 NaN                  NaN   \n",
      "160                 478                 NaN                  NaN   \n",
      "85                  479                 NaN                  NaN   \n",
      "0                   480                 NaN                  NaN   \n",
      "\n",
      "     std_test_accuracy  std_train_accuracy  mean_fit_time  \\\n",
      "196           0.040948            0.007202       0.059422   \n",
      "57            0.048311            0.009570       0.045088   \n",
      "199           0.082642            0.003118       0.045311   \n",
      "230           0.032996            0.005011       0.054484   \n",
      "38            0.050286            0.005558       0.048613   \n",
      "..                 ...                 ...            ...   \n",
      "81                 NaN                 NaN       0.051330   \n",
      "80                 NaN                 NaN       0.048123   \n",
      "160                NaN                 NaN       0.045299   \n",
      "85                 NaN                 NaN       0.052457   \n",
      "0                  NaN                 NaN       0.052536   \n",
      "\n",
      "                                                params  \n",
      "196  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "57   {'criterion': 'gini', 'max_features': 'sqrt', ...  \n",
      "199  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "230  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "38   {'criterion': 'gini', 'max_features': 'sqrt', ...  \n",
      "..                                                 ...  \n",
      "81   {'criterion': 'gini', 'max_features': 'log2', ...  \n",
      "80   {'criterion': 'gini', 'max_features': 'log2', ...  \n",
      "160  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "85   {'criterion': 'gini', 'max_features': 'log2', ...  \n",
      "0    {'criterion': 'gini', 'max_features': 'sqrt', ...  \n",
      "\n",
      "[480 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from analysis.classifiers.dt import build_parameters\n",
    "\n",
    "hyper_params = build_parameters(\n",
    "    train_x=pipeline.train_x,\n",
    "    train_y=pipeline.train_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0c813",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec94d63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;sqrt&#x27;,\n",
       "                       min_samples_leaf=2, min_samples_split=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_features=&#x27;sqrt&#x27;,\n",
       "                       min_samples_leaf=2, min_samples_split=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_features='sqrt',\n",
       "                       min_samples_leaf=2, min_samples_split=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis.classifiers.dt import build_model\n",
    "\n",
    "decision_tree = build_model(\n",
    "    train_x=pipeline.train_x,\n",
    "    train_y=pipeline.train_y,\n",
    "    best_params=hyper_params\n",
    ")\n",
    "decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623a11c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4e8158",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from analysis.classifiers.dt import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ea0824",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         A1A       0.94      0.97      0.95        32\n",
      "     DIABETE       0.71      0.77      0.74        44\n",
      "          GS       0.12      0.14      0.13         7\n",
      "         MCM       0.75      0.43      0.55         7\n",
      "        NALD       0.29      0.20      0.24        10\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.56      0.50      0.52       100\n",
      "weighted avg       0.70      0.71      0.70       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation = evaluate_model(\n",
    "    decision_tree=decision_tree,\n",
    "    test_x=pipeline.test_x,\n",
    "    test_y=pipeline.test_y\n",
    ")\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1fc8a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3adda66",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(decision_tree, filled=True, out_file=\"tree.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17504635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
