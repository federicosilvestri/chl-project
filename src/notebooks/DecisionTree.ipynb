{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2ba176",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756cfed2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# adding the project root inside the python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d631aee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The path where the dataset are stored\n",
    "DATASET_PATH: str = \"../../dataset/first_disease_sel/\"\n",
    "DISEASE_COLNAME: str = 'DISEASE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30ec15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Executing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c5f214",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Pipeline already executed, found dataset inside /tmp/chl\n",
      "INFO:root:Splitting dataset\n",
      "INFO:root:Pipeline executed\n"
     ]
    }
   ],
   "source": [
    "from analysis.preprocess import PreprocessPipeline\n",
    "\n",
    "pipeline = PreprocessPipeline(\n",
    "    datasets_path=DATASET_PATH,\n",
    "    disease_col_name=DISEASE_COLNAME\n",
    ")\n",
    "pipeline.execute_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab377e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building the Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d460c2",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3cc11e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Executing Grid Search for Decision Tree\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "480 fits failed out of a total of 2400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "480 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 247, in fit\n",
      "    check_scalar(\n",
      "  File \"/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_leaf == 0, must be >= 1.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.65536723 0.58542373\n",
      " 0.66553672 0.66248588 0.65898305 0.6720339  0.64903955 0.6419774\n",
      " 0.66220339 0.66915254 0.65858757 0.68525424 0.68231638 0.65898305\n",
      " 0.64576271 0.70220339 0.66248588 0.66887006 0.69892655 0.66847458\n",
      " 0.69259887 0.6220339  0.66220339 0.69870056 0.63576271 0.64881356\n",
      " 0.6420339  0.6520904  0.63553672 0.67220339 0.62909605 0.65864407\n",
      " 0.66536723 0.63548023 0.67242938 0.69242938 0.68214689 0.66926554\n",
      " 0.65237288 0.66231638 0.65887006 0.64881356 0.64220339 0.67898305\n",
      " 0.69553672 0.67242938 0.69576271 0.62214689 0.68220339 0.67564972\n",
      " 0.67231638 0.66536723 0.66892655 0.68920904 0.64231638 0.66248588\n",
      " 0.69892655 0.62881356 0.68265537 0.6620904  0.66559322 0.64214689\n",
      " 0.70248588 0.68553672        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65536723 0.63548023 0.60519774 0.60875706 0.6319774  0.62553672\n",
      " 0.63536723 0.60542373 0.59858757 0.6520904  0.60531073 0.59508475\n",
      " 0.61531073 0.65220339 0.64909605 0.59875706 0.66898305 0.63502825\n",
      " 0.66581921 0.63892655 0.65870056 0.6219774  0.65220339 0.66570621\n",
      " 0.61881356 0.61180791 0.67548023 0.62519774 0.64248588 0.6020339\n",
      " 0.57847458 0.63175141 0.61858757 0.61898305 0.61553672 0.62548023\n",
      " 0.59525424 0.65225989 0.64553672 0.5819774  0.64581921 0.63225989\n",
      " 0.64847458 0.63237288 0.62903955 0.60836158 0.63237288 0.64858757\n",
      " 0.67231638 0.66231638 0.66542373 0.6219774  0.62525424 0.64898305\n",
      " 0.64576271 0.64531073 0.64847458 0.66519774 0.67559322 0.67576271\n",
      " 0.65875706 0.63576271 0.64536723 0.61536723        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.66875706 0.64570621 0.70559322 0.66564972\n",
      " 0.67237288 0.66237288 0.69909605 0.65559322 0.69559322 0.63553672\n",
      " 0.70570621 0.63553672 0.66559322 0.68564972 0.66587571 0.64248588\n",
      " 0.6520904  0.62881356 0.71248588 0.63502825 0.69214689 0.68231638\n",
      " 0.66892655 0.63553672 0.70576271 0.6620904  0.66570621 0.68220339\n",
      " 0.67231638 0.64531073 0.69920904 0.63548023 0.70576271 0.64220339\n",
      " 0.68892655 0.62531073 0.64870056 0.6859322  0.68559322 0.70254237\n",
      " 0.71237288 0.71248588 0.68898305 0.6620904  0.69932203 0.65581921\n",
      " 0.70881356 0.66237288 0.71892655 0.66864407 0.65570621 0.67576271\n",
      " 0.71242938 0.69248588 0.70237288 0.65231638 0.66564972 0.64548023\n",
      " 0.71903955 0.66553672 0.71242938 0.64564972 0.70231638 0.71881356\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.61531073 0.64531073\n",
      " 0.6520339  0.63858757 0.64220339 0.61225989 0.61180791 0.6520339\n",
      " 0.68570621 0.63881356 0.66214689 0.57548023 0.65214689 0.62531073\n",
      " 0.64881356 0.65548023 0.64214689 0.58875706 0.64881356 0.62514124\n",
      " 0.68898305 0.6419209  0.63248588 0.69881356 0.64858757 0.65548023\n",
      " 0.67892655 0.65531073 0.66570621 0.62525424 0.66887006 0.63542373\n",
      " 0.68564972 0.60225989 0.67237288 0.63225989 0.6119774  0.61841808\n",
      " 0.63225989 0.67237288 0.64892655 0.65920904 0.71237288 0.63570621\n",
      " 0.67581921 0.67898305 0.61898305 0.61542373 0.65525424 0.62525424\n",
      " 0.66898305 0.6620904  0.66559322 0.66231638 0.62581921 0.66248588\n",
      " 0.67231638 0.61875706 0.60519774 0.62870056 0.6319774  0.5720339\n",
      " 0.6420904  0.63559322        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.63892655 0.67570621 0.67898305 0.63553672 0.67220339 0.68225989\n",
      " 0.62892655 0.64559322 0.67864407 0.68214689 0.65864407 0.66892655\n",
      " 0.69265537 0.68915254 0.70909605 0.68587571 0.66909605 0.60220339\n",
      " 0.68225989 0.6519209  0.65231638 0.69915254 0.69926554 0.63531073\n",
      " 0.6720904  0.63525424 0.66576271 0.66548023 0.74259887 0.65581921\n",
      " 0.70915254 0.65898305 0.65214689 0.72926554 0.71225989 0.73926554\n",
      " 0.68881356 0.67576271 0.72564972 0.67559322 0.68225989 0.68909605\n",
      " 0.68553672 0.6520904  0.67570621 0.68915254 0.68231638 0.70581921\n",
      " 0.71881356 0.67248588 0.65570621 0.68898305 0.70887006 0.69875706\n",
      " 0.67898305 0.68214689 0.66225989 0.66887006 0.66559322 0.6220904\n",
      " 0.67564972 0.71559322 0.69564972 0.68231638        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.58536723 0.59231638 0.63898305 0.6220904\n",
      " 0.59548023 0.5619209  0.64542373 0.63881356 0.64892655 0.61898305\n",
      " 0.64903955 0.63881356 0.61186441 0.6720339  0.60497175 0.61881356\n",
      " 0.70920904 0.61497175 0.62887006 0.65237288 0.65553672 0.62519774\n",
      " 0.64553672 0.57870056 0.62864407 0.68248588 0.65225989 0.59220339\n",
      " 0.64587571 0.62858757 0.62214689 0.60214689 0.64553672 0.68892655\n",
      " 0.62881356 0.62531073 0.65587571 0.63898305 0.66254237 0.68570621\n",
      " 0.66220339 0.63214689 0.66903955 0.6220339  0.62903955 0.6420339\n",
      " 0.60186441 0.62887006 0.69881356 0.6119774  0.64892655 0.68576271\n",
      " 0.65531073 0.64514124 0.63887006 0.64887006 0.65220339 0.65214689\n",
      " 0.68875706 0.61864407 0.65903955 0.67214689 0.68570621 0.67220339]\n",
      "  warnings.warn(\n",
      "/home/federicosilvestri/Projects/Vedrai/chl-project/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 0.99079498 0.97826709 0.97492329 0.96069735 0.96571478 0.94480474\n",
      " 0.95401325 0.94314854 0.94314156 0.91221757 0.93811367 0.91303696\n",
      " 0.933947   0.89214435 0.95819038 0.94314854 0.9531834  0.931447\n",
      " 0.95484658 0.93730823 0.94397141 0.91973152 0.94647838 0.90050209\n",
      " 0.93310669 0.90300558 0.91972803 0.88545676 0.92224547 0.89549861\n",
      " 0.92641911 0.90300209 0.94063459 0.89466179 0.93059972 0.88546374\n",
      " 0.93143654 0.89715481 0.92725593 0.88796025 0.91472455 0.88544282\n",
      " 0.91388424 0.87877266 0.91555788 0.87207113 0.89717573 0.86373431\n",
      " 0.91387727 0.86121688 0.90634937 0.83778591 0.90550558 0.85704672\n",
      " 0.91054393 0.86706764 0.90218968 0.86536611 0.90717225 0.86706764\n",
      " 0.89800907 0.83863319        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.98495467 0.9657357  0.9623675  0.94817294\n",
      " 0.94985007 0.90885635 0.94483961 0.88711297 0.93562064 0.87877964\n",
      " 0.92141911 0.85117503 0.90050907 0.84864365 0.93896792 0.89464435\n",
      " 0.93310669 0.8904463  0.93395049 0.88793933 0.93141911 0.87206416\n",
      " 0.91137727 0.85619596 0.91554045 0.84615411 0.89633194 0.83695607\n",
      " 0.89214435 0.81107043 0.90216527 0.83527197 0.90549512 0.82189679\n",
      " 0.90887029 0.84282078 0.90299861 0.82355997 0.90969665 0.83360879\n",
      " 0.90384589 0.83029289 0.88712692 0.81523361 0.8804219  0.80599721\n",
      " 0.87625174 0.78597978 0.88293584 0.8060251  0.8670537  0.80267085\n",
      " 0.88211646 0.78763947 0.88043236 0.79766736 0.86874128 0.79684449\n",
      " 0.87959554 0.78346583 0.86874128 0.77927824        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.99331241 0.98913877\n",
      " 0.98243375 0.97407601 0.97908647 0.95819038 0.97156904 0.94649582\n",
      " 0.96403417 0.92141562 0.95737448 0.92893305 0.95735704 0.90050209\n",
      " 0.9673954  0.93644351 0.95986053 0.94901674 0.96906206 0.93645397\n",
      " 0.95986402 0.93895746 0.95065551 0.92475244 0.93979777 0.90886681\n",
      " 0.94982915 0.91054742 0.94565202 0.88462692 0.94648187 0.91388075\n",
      " 0.94230823 0.91055439 0.93812413 0.91389121 0.95066597 0.90134937\n",
      " 0.94314156 0.91221757 0.92475244 0.89550209 0.93478731 0.8829463\n",
      " 0.91890516 0.8737378  0.91806485 0.87625872 0.92642259 0.8670537\n",
      " 0.93309972 0.87207113 0.91137029 0.86788703 0.91386681 0.86203975\n",
      " 0.92975941 0.87878661 0.92474547 0.86703975 0.91639121 0.85369596\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 0.98829847 0.97742329 0.97993375 0.9523431  0.9632113  0.92559275\n",
      " 0.95568689 0.88379707 0.94399233 0.87372036 0.92892259 0.84366109\n",
      " 0.89715132 0.82693515 0.94647141 0.89461994 0.93896444 0.88881799\n",
      " 0.94648536 0.90217922 0.94146095 0.88629358 0.92558229 0.87289749\n",
      " 0.91639121 0.84367155 0.9230788  0.84449093 0.91806834 0.82607392\n",
      " 0.92057531 0.8394735  0.92307183 0.83361576 0.92475244 0.82525105\n",
      " 0.93060321 0.84533473 0.92390167 0.84783124 0.90635635 0.82189679\n",
      " 0.90466876 0.83193863 0.90131799 0.80935844 0.89046025 0.79598675\n",
      " 0.87876569 0.78765342 0.89635635 0.79849372 0.88626569 0.80017085\n",
      " 0.89379358 0.80264644 0.87373431 0.79097978 0.88711994 0.79012901\n",
      " 0.88461994 0.79933054        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 1.         1.         0.99080544 0.98578103 0.98745816 0.97993375\n",
      " 0.97741283 0.96071478 0.97491632 0.95067643 0.96404114 0.93058926\n",
      " 0.94316946 0.92391213 0.96154463 0.91134589 0.96404463 0.94398536\n",
      " 0.96739191 0.93895746 0.96739191 0.95400279 0.95903068 0.92726987\n",
      " 0.95902371 0.91555091 0.94567294 0.91806485 0.94398187 0.90552301\n",
      " 0.93562413 0.88714086 0.93896095 0.9105265  0.94649233 0.90635286\n",
      " 0.945659   0.91053347 0.95652022 0.91053347 0.94229428 0.91221409\n",
      " 0.93226987 0.89465481 0.92392259 0.88293236 0.91888424 0.88294282\n",
      " 0.91889819 0.86539749 0.91388424 0.87376918 0.92056834 0.87039052\n",
      " 0.92474895 0.8611855  0.93060321 0.87374128 0.93143305 0.87458508\n",
      " 0.91805439 0.86790446 0.91721757 0.87458856        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.98578103 0.98076709\n",
      " 0.97827057 0.94146792 0.97073222 0.91804393 0.95987448 0.89130056\n",
      " 0.93645397 0.87374477 0.92308577 0.85785565 0.91137727 0.83779289\n",
      " 0.94396792 0.90635635 0.95067294 0.89380753 0.94900279 0.90220363\n",
      " 0.94733264 0.88879358 0.93395746 0.86538703 0.92642608 0.85537308\n",
      " 0.91387029 0.84533821 0.90466527 0.84116109 0.92392957 0.85619596\n",
      " 0.91973152 0.83781032 0.92140865 0.84531729 0.91805788 0.83360879\n",
      " 0.90803347 0.84700139 0.91138424 0.83112622 0.90133543 0.82105997\n",
      " 0.8929742  0.79766039 0.89547768 0.7834484  0.8779219  0.80017782\n",
      " 0.88796374 0.7935007  0.88545676 0.81439679 0.89214435 0.79600767\n",
      " 0.8879463  0.78511158 0.88211646 0.82358787 0.87709554 0.79263947]\n",
      "  warnings.warn(\n",
      "INFO:root:Grid search terminated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Report of GridSearch\n",
      "INFO:root:     rank_test_accuracy  mean_test_accuracy  mean_train_accuracy  \\\n",
      "364                   1            0.742599             0.943982   \n",
      "371                   2            0.739266             0.906353   \n",
      "369                   3            0.729266             0.910526   \n",
      "374                   4            0.725650             0.956520   \n",
      "234                   5            0.719040             0.929759   \n",
      "..                  ...                 ...                  ...   \n",
      "85                  476                 NaN                  NaN   \n",
      "84                  477                 NaN                  NaN   \n",
      "83                  478                 NaN                  NaN   \n",
      "81                  479                 NaN                  NaN   \n",
      "0                   480                 NaN                  NaN   \n",
      "\n",
      "     std_test_accuracy  std_train_accuracy  mean_fit_time  \\\n",
      "364           0.052800            0.013894       0.051986   \n",
      "371           0.023680            0.005700       0.043404   \n",
      "369           0.043095            0.010516       0.043526   \n",
      "374           0.040995            0.004281       0.051350   \n",
      "234           0.037254            0.006754       0.053632   \n",
      "..                 ...                 ...            ...   \n",
      "85                 NaN                 NaN       0.049218   \n",
      "84                 NaN                 NaN       0.049624   \n",
      "83                 NaN                 NaN       0.049362   \n",
      "81                 NaN                 NaN       0.044750   \n",
      "0                  NaN                 NaN       0.051354   \n",
      "\n",
      "                                                params  \n",
      "364  {'criterion': 'log_loss', 'max_features': 'sqr...  \n",
      "371  {'criterion': 'log_loss', 'max_features': 'sqr...  \n",
      "369  {'criterion': 'log_loss', 'max_features': 'sqr...  \n",
      "374  {'criterion': 'log_loss', 'max_features': 'sqr...  \n",
      "234  {'criterion': 'entropy', 'max_features': 'sqrt...  \n",
      "..                                                 ...  \n",
      "85   {'criterion': 'gini', 'max_features': 'log2', ...  \n",
      "84   {'criterion': 'gini', 'max_features': 'log2', ...  \n",
      "83   {'criterion': 'gini', 'max_features': 'log2', ...  \n",
      "81   {'criterion': 'gini', 'max_features': 'log2', ...  \n",
      "0    {'criterion': 'gini', 'max_features': 'sqrt', ...  \n",
      "\n",
      "[480 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from analysis.classifiers.dt import build_parameters\n",
    "\n",
    "hyper_params = build_parameters(\n",
    "    train_x=pipeline.train_x,\n",
    "    train_y=pipeline.train_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0c813",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from analysis.classifiers.dt import build_model\n",
    "\n",
    "decision_tree = build_model(\n",
    "    train_x=pipeline.train_x,\n",
    "    train_y=pipeline.train_y,\n",
    "    best_params=hyper_params\n",
    ")\n",
    "decision_tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from analysis.classifiers.dt import evaluate_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation = evaluate_model(\n",
    "    decision_tree=decision_tree,\n",
    "    test_x=pipeline.test_x,\n",
    "    test_y=pipeline.test_y\n",
    ")\n",
    "print(evaluation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17504635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}